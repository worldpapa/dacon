{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true [3 9 0 5 2 7 7 2 2 0 3 7 3 3 0 0 2 1 1 3 4 7 2 2 1 1 4 3 6 0 6 0 6 4 2 1 8\n",
      " 4 5 9 7 7 1 5 5 1 9 6 6 7 9 6 8 9 8 7 1 1 2 2 4 0 8 9 7 4 6 3 3 5 8 6 5 9\n",
      " 4 3 9 6 8 1 2 5 7 4 9 4 8 3 4 0 8 5 6 8 0 5 5 9 0 8]\n",
      "pred [8 8 0 5 2 7 7 2 2 0 3 7 3 3 0 6 2 1 1 7 4 6 2 2 1 1 4 3 6 2 6 0 6 4 2 1 8\n",
      " 4 5 9 7 7 1 5 5 1 9 6 6 6 9 7 8 9 8 7 1 9 2 2 4 0 8 9 6 5 3 3 3 5 8 6 5 9\n",
      " 4 0 9 6 3 1 2 5 7 4 9 4 8 3 4 6 8 5 6 8 0 5 5 3 0 8]\n",
      "Private accuracy Score : 0.84\n",
      "---------------------------------------------------------\n",
      "\n",
      "true [0 9 8 2 7 9 5 3 1 2 9 8 1 3 1 8 8 6 4 1 3 4 6 2 4 7 5 4 5 9 9 7 2 7 0 7 1\n",
      " 5 9 7 0 6 5 2 6 1 7 0 0 3 5 3 9 1 7 9 7 4 0 1 6 3 5 8 8 6 2 6 9 4 3 4 5 8\n",
      " 0 0 0 5 6 1 9 5 7 1 2 2 6 4 4 0 2 8 3 8 4 3 6 2 3 8]\n",
      "pred [0 9 8 2 3 9 5 3 1 2 9 8 1 3 1 8 8 6 4 1 3 1 3 2 4 7 5 4 5 9 9 7 2 7 0 7 1\n",
      " 5 9 7 0 6 5 2 6 1 7 0 0 3 5 3 9 1 7 9 7 4 0 1 6 3 5 8 8 6 7 6 9 5 3 1 5 8\n",
      " 0 0 0 5 6 1 9 5 7 1 2 2 0 4 5 0 2 8 3 8 4 3 6 2 3 8]\n",
      "Public accuracy Score : 0.92\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def nmae(true_df, pred_df):\n",
    "    target_idx = true_df.iloc[:,0]\n",
    "    pred_df = pred_df[pred_df.iloc[:,0].isin(target_idx)]\n",
    "    pred_df = pred_df.sort_values(by=[pred_df.columns[0]], ascending=[True])\n",
    "    true_df = true_df.sort_values(by=[true_df.columns[0]], ascending=[True])\n",
    "    true = true_df.iloc[:,1].to_numpy()\n",
    "    pred = pred_df.iloc[:,1].to_numpy()\n",
    "    #eps = 0.00001\n",
    "    #score = np.mean(np.abs(true-pred)/(true+eps))\n",
    "    mae = np.mean(np.abs(true-pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    \n",
    "    return score\n",
    "\n",
    "def accuracy(true_df, pred_df):\n",
    "    target_idx = true_df.iloc[:,0]\n",
    "    pred_df = pred_df[pred_df.iloc[:,0].isin(target_idx)]\n",
    "    pred_df = pred_df.sort_values(by=[pred_df.columns[0]], ascending=[True])\n",
    "    true_df = true_df.sort_values(by=[true_df.columns[0]], ascending=[True])\n",
    "    true = true_df.iloc[:,1].to_numpy()\n",
    "    pred = pred_df.iloc[:,1].to_numpy()\n",
    "    print('true', true)\n",
    "    print('pred', pred)\n",
    "    score = np.mean(true==pred)\n",
    "    return score\n",
    "\n",
    "def calc_score(private_answer, public_answer, pred):\n",
    "    import pandas as pd\n",
    "    all_predicted = pd.read_csv(\"{}\".format(pred))\n",
    "    private_answer = pd.read_csv(\"{}\".format(private_answer))\n",
    "    public_answer = pd.read_csv(\"{}\".format(public_answer))\n",
    "\n",
    "    # Private score\n",
    "    #print(f'Private nmae Score : {nmae(private_answer, all_predicted)}')\n",
    "    print(f'Private accuracy Score : {accuracy(private_answer, all_predicted)}')\n",
    "    \n",
    "#     targets = private_answer.id\n",
    "#     private_predicted = all_predicted.loc[all_predicted['id'].isin(targets)]\n",
    "#     private_predicted = private_predicted.drop(\"id\",axis=1)\n",
    "#     private_answer = private_answer.drop(\"id\",axis=1)\n",
    "#     print(f'Private RMSE Score : {mean_squared_error(private_answer,private_predicted,squared=False)}')\n",
    "    \n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    # Public score\n",
    "    #print(f'Public nmae Score : {nmae(public_answer, all_predicted)}')\n",
    "    print(f'Public accuracy Score : {accuracy(public_answer, all_predicted)}')\n",
    "    \n",
    "#     targets = public_answer.id\n",
    "#     public_predicted = all_predicted.loc[all_predicted['id'].isin(targets)]\n",
    "#     public_predicted = public_predicted.drop(\"id\",axis=1)\n",
    "#     public_answer = public_answer.drop(\"id\",axis=1)\n",
    "#     print(f'Public RMSE Score : {mean_squared_error(public_answer,public_predicted,squared=False)}')\n",
    "\n",
    "\n",
    "calc_score('data2/private_answer.csv', 'data2/public_answer.csv', 'data/saved/submit2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
