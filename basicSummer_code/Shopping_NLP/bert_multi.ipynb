{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea10755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 27 17:51:37 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  On   | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   26C    P0    41W / 250W |  17040MiB / 32510MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-PCIE...  On   | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   25C    P0    40W / 250W |   2375MiB / 32510MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      6875      C   /home/ubuntu/anaconda3/bin/python3.8        1383MiB |\n",
      "|    0     11490      C   ...ubuntu/anaconda3/envs/sesang/bin/python  4287MiB |\n",
      "|    0     18039      C   /home/ubuntu/anaconda3/bin/python3.8        4475MiB |\n",
      "|    1     18039      C   /home/ubuntu/anaconda3/bin/python3.8        2363MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f592f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#from transformers import BertTokenizer\n",
    "from transformers import RobertaTokenizerFast, RobertaModel\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ff6678",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0, 1\"  # Set the GPU 2 to use, 멀티 gpu\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd00d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "#GPU 체크 및 할당\n",
    "if torch.cuda.is_available():    \n",
    "    #device = torch.device(\"cuda:0\")\n",
    "    print('Device:', device)\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e1697e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'MAX_LEN':140,\n",
    "    'MODEL_NAME':'roberta-base',\n",
    "    'EPOCHS':20,\n",
    "    'LEARNING_RATE':1e-5,\n",
    "    'BATCH_SIZE':8,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc69df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95bde162",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(CFG['MODEL_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27e5e943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (25000, 3)\n",
      "test shape: (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "## main 및 test 로드\n",
    "#csv 형식의 training 데이터를 로드합니다.\n",
    "import pandas as pd \n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "#데이터 살펴보기 위해 데이터 최상단의 5줄을 표시합니다.\n",
    "train.head() \n",
    "print('train shape:',train.shape)\n",
    "print('test shape:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe579e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviews</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>채소가 약간 시들어 있어요</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>발톱 두껍고 단단한 분들 써도 소용없어요 이 테이프 물렁거리고 힘이없어서 들어 올리...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>부들부들 좋네요 입어보고 시원하면 또 살게요</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>이런 1. 8 골드 주라니깐 파란개 오네 회사전화걸어도 받지도 않고 머하자는거임?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>검수도 없이 보내구 불량 배송비 5000원 청구하네요 완전별로 별하나도 아까워요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            reviews  target\n",
       "0   0                                     채소가 약간 시들어 있어요       2\n",
       "1   1  발톱 두껍고 단단한 분들 써도 소용없어요 이 테이프 물렁거리고 힘이없어서 들어 올리...       1\n",
       "2   2                           부들부들 좋네요 입어보고 시원하면 또 살게요       5\n",
       "3   3      이런 1. 8 골드 주라니깐 파란개 오네 회사전화걸어도 받지도 않고 머하자는거임?       1\n",
       "4   4       검수도 없이 보내구 불량 배송비 5000원 청구하네요 완전별로 별하나도 아까워요       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_total = pd.read_csv('data/test_total.csv')\n",
    "test_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7227a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       25000 non-null  int64 \n",
      " 1   reviews  25000 non-null  object\n",
      " 2   target   25000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 586.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b89958",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'][train['target'] == 1] = 0 ## label : 10-1 -> 10\n",
    "train['target'][train['target'] == 2] = 1 ## Label : 10-2 -> 0\n",
    "train['target'][train['target'] == 4] = 2 ## Label : 10-2 -> 0\n",
    "train['target'][train['target'] == 5] = 3 ## Label : 10-2 -> 0\n",
    "test_total['target'][test_total['target'] == 1] = 0 ## label : 10-1 -> 10\n",
    "test_total['target'][test_total['target'] == 2] = 1 ## Label : 10-2 -> 0\n",
    "test_total['target'][test_total['target'] == 4] = 2 ## Label : 10-2 -> 0\n",
    "test_total['target'][test_total['target'] == 5] = 3 ## Label : 10-2 -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9abda728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text_list):\n",
    "    resample_list = []\n",
    "    for text in text_list:\n",
    "        text = text.lower()\n",
    "        text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        resample_list.append(text)\n",
    "    return resample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df1840fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['reviews'] = preprocessing(train['reviews'].values)\n",
    "test['reviews'] = preprocessing(test['reviews'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "067c35c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encode_data(code_list):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in tqdm(code_list):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            text = sent,                     # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = CFG['MAX_LEN'],           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                        )\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks\n",
    "\n",
    "def get_data(dataframe):\n",
    "    code, mask = get_encode_data(dataframe['reviews'].values)\n",
    "    return code, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbb850ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:08<00:00, 2946.09it/s]\n",
      "100%|██████████| 25000/25000 [00:08<00:00, 2997.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_code_ids, train_code_masks = get_data(train)\n",
    "test_code_ids, test_code_masks = get_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ad66f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, code_ids, code_masks, labels, train_mode):\n",
    "        self.code_ids = code_ids\n",
    "        self.code_masks = code_masks\n",
    "        self.labels = labels\n",
    "        self.train_mode = train_mode\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        code_input_ids = self.code_ids[index]\n",
    "        code_input_masks = self.code_masks[index]\n",
    "        \n",
    "        if self.train_mode:\n",
    "            label = self.labels[index]\n",
    "            return code_input_ids, code_input_masks, label\n",
    "        else:\n",
    "            return code_input_ids, code_input_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.code_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4b48399",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_code_ids, train_code_masks, train['target'].values, True)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=8)\n",
    "\n",
    "test_dataset = CustomDataset(test_code_ids, test_code_masks, test_total['target'].values, True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9813e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaSimilarModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaSimilarModel, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(CFG['MODEL_NAME'])\n",
    "        self.classifier = nn.Linear(768, 4)\n",
    "\n",
    "    def forward(self, code_input_id, code_mask):\n",
    "        _, feature = self.roberta(input_ids= code_input_id, attention_mask=code_mask, return_dict=False)\n",
    "        \n",
    "        output = self.classifier(feature)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbe01f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim # 최적화 알고리즘들이 포함힘\n",
    "\n",
    "model = RobertaSimilarModel()\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr= CFG[\"LEARNING_RATE\"] )#0.001\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dfae249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gc\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afba11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, scheduler, device): \n",
    "    #model.to(device)\n",
    "    #model = nn.DataParallel(model)\n",
    "    NGPU = torch.cuda.device_count()\n",
    "    if NGPU > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=list(range(NGPU)))\n",
    "    #torch.multiprocessing.set_start_method('spawn')\n",
    "    model.to(device)\n",
    "    \n",
    "    n = len(train_loader)\n",
    "    \n",
    "    #Loss Function 정의\n",
    "    #criterion = nn.CrossEntropyLoss().to(device)\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(1,CFG[\"EPOCHS\"]+1): #에포크 설정\n",
    "        model.train() #모델 학습\n",
    "        running_loss = 0.0\n",
    "            \n",
    "        for code_input_id, code_input_mask, label in tqdm(iter(train_loader)):\n",
    "            code_input_id, code_input_mask = code_input_id.to(device), code_input_mask.to(device) #배치 데이터\n",
    "            label = label.to(device)\n",
    "            optimizer.zero_grad() #배치마다 optimizer 초기화\n",
    "        \n",
    "            # Data -> Model -> Output\n",
    "            logit = model(code_input_id, code_input_mask) #예측값 산출\n",
    "            #print('model :', logit)\n",
    "            #print('label :', label)\n",
    "            \n",
    "            loss = criterion(logit, label) #손실함수 계산\n",
    "            \n",
    "            #print('loss :', loss)\n",
    "            \n",
    "            # 역전파\n",
    "            loss.backward() #손실함수 기준 역전파 \n",
    "            optimizer.step() #가중치 최적화\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        #print('len :', len(train_loader))\n",
    "            #print('loss :', running_loss)\n",
    "            \n",
    "        print('[%d] Train loss: %.10f' %(epoch, running_loss / len(train_loader)))\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        #Validation set 평가\n",
    "        model.eval() #evaluation 과정에서 사용하지 않아야 하는 layer들을 알아서 off 시키도록 하는 함수\n",
    "        vali_loss = 0.0\n",
    "        correct = 0\n",
    "        with torch.no_grad(): #파라미터 업데이트 안하기 때문에 no_grad 사용\n",
    "            for code_input_id, code_input_mask, label in tqdm(iter(test_loader)):\n",
    "                code_input_id, code_input_mask = code_input_id.to(device), code_input_mask.to(device)\n",
    "                label = label.to(device)\n",
    "                logit = model(code_input_id, code_input_mask)\n",
    "                vali_loss += criterion(logit, label)\n",
    "                pred = logit.argmax(dim=1, keepdim=True)  #4개의 class중 가장 값이 높은 것을 예측 label로 추출\n",
    "                correct += pred.eq(label.view_as(pred)).sum().item() #예측값과 실제값이 맞으면 1 아니면 0으로 합산\n",
    "        vali_acc = 100 * correct / len(test_loader.dataset)\n",
    "        print('Vail set: Loss: {:.4f}, Accuracy: {}/{} ( {:.0f}%)\\n'.format(vali_loss / len(test_loader), correct, len(test_loader.dataset), 100 * correct / len(test_loader.dataset)))\n",
    "        \n",
    "        #베스트 모델 저장\n",
    "        if best_acc < vali_acc:\n",
    "            best_acc = vali_acc\n",
    "            torch.save(model.state_dict(), './saved/best_model.pth') #이 디렉토리에 best_model.pth을 저장\n",
    "            print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed5f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [08:42<00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 1.0805524924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 1806/3125 [02:07<01:31, 14.39it/s]"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, train_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8bcff4-4c6c-4874-a133-a66bc49f383e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesang",
   "language": "python",
   "name": "sesang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
