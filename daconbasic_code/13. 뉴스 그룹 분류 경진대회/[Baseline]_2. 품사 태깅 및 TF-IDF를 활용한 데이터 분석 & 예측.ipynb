{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snO_-EVUiUiv"
   },
   "source": [
    "# 두 번째 베이스라인\n",
    "\n",
    "스포츠, 사회, 과학, 정치, 종교 등 20개의 카테고리의 토픽을 분류하는\n",
    "\n",
    "영어 뉴스 데이터를 통해 뉴스 그룹을 분류하는 대회입니다.\n",
    "\n",
    "이번 베이스라인에서는 TF-IDF를 활용해 문장 벡터를 만들기 위한\n",
    "\n",
    "TfidfVectorizer 을 적용하여 모델의 성능을 높여보겠습니다.\n",
    "\n",
    "베이스라인을 통해 자연어 처리 기초에 입문해보세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOWORo2sijgT"
   },
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1648442939829,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "xNMcfxP0idCZ",
    "outputId": "e90ce08f-24dc-4f32-f13a-a913fa1ace9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nThey were, and even if Washington might cons...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We run \"SpaceNews &amp; Views\" on our STAREACH BBS...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n\\nNot to worry.  The Masons have been demo...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Only Brendan McKay, or maybe ARF, would come t...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Help: I am running some sample problems from O...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target\n",
       "0   0  \\nThey were, and even if Washington might cons...      10\n",
       "1   1  We run \"SpaceNews & Views\" on our STAREACH BBS...      14\n",
       "2   2  \\n\\n\\nNot to worry.  The Masons have been demo...      19\n",
       "3   3  Only Brendan McKay, or maybe ARF, would come t...      17\n",
       "4   4  Help: I am running some sample problems from O...       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#csv 형식의 training 데이터를 로드합니다.\n",
    "import pandas as pd \n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "#데이터 살펴보기 위해 데이터 최상단의 5줄을 표시합니다.\n",
    "train.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7cAncqCBvt6"
   },
   "source": [
    "# 결측치 확인\n",
    "\n",
    "결측치(NA: Not Available)란 값이 누락된 데이터를 말합니다.\n",
    "\n",
    "보다 정확한 분석을 하기 위해서는 데이터의 결측치를 확인하고 적절히 처리해주어야 합니다.\n",
    "\n",
    "이번 데이터에 결측치가 있나 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1648442940215,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "mSeNSz9OkePT",
    "outputId": "8a30ee68-73d1-464d-c0db-c5bfc2f5ee91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치가 존재하지 않습니다\n"
     ]
    }
   ],
   "source": [
    "def check_missing_col(dataframe):\n",
    "    missing_col = []\n",
    "    for col in dataframe.columns:\n",
    "        missing_values = sum(dataframe[col].isna())\n",
    "        is_missing = True if missing_values >= 1 else False\n",
    "        if is_missing:\n",
    "            print(f'결측치가 있는 컬럼은: {col} 입니다')\n",
    "            print(f'해당 컬럼에 총 {missing_values} 개의 결측치가 존재합니다.')\n",
    "            missing_col.append([col, dataframe[col].dtype])\n",
    "    if missing_col == []:\n",
    "        print('결측치가 존재하지 않습니다')\n",
    "    return missing_col\n",
    "\n",
    "missing_col = check_missing_col(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSP6-CrmbsBx"
   },
   "source": [
    "이제 본격적으로 모델을 설계하기 위해 데이터를 문서와 label 로 나누어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1648442940215,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "pQIPVi3XlNY9"
   },
   "outputs": [],
   "source": [
    "X = train.text #training 데이터에서 문서 추출\n",
    "y = train.target #training 데이터에서 라벨 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1648442940215,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "kPrOPG-dlQlw",
    "outputId": "bc8b3b5d-1bb2-4649-aafc-90e6641b21ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\nThey were, and even if Washington might cons...\n",
       "1    We run \"SpaceNews & Views\" on our STAREACH BBS...\n",
       "2    \\n\\n\\nNot to worry.  The Masons have been demo...\n",
       "3    Only Brendan McKay, or maybe ARF, would come t...\n",
       "4    Help: I am running some sample problems from O...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head() #데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1648442940216,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "AukNWGBBlR0q",
    "outputId": "888c6b4c-4e62-4161-e0ae-6d5220233cba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    14\n",
       "2    19\n",
       "3    17\n",
       "4     5\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head() #데이터 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-EJyJSGFCFc"
   },
   "source": [
    "# Text 기초 전처리\n",
    "\n",
    "EDA 파트에서 했던 것 처럼 Text를 전처리 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1648442940216,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "XD6Ikas7lar_",
    "outputId": "6a323b01-986c-46cf-c21d-02e13ca18c07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       \\nThey were, and even if Washington might cons...\n",
       "1       We run \"SpaceNews & Views\" on our STAREACH BBS...\n",
       "2       \\n\\n\\nNot to worry.  The Masons have been demo...\n",
       "3       Only Brendan McKay, or maybe ARF, would come t...\n",
       "4       Help: I am running some sample problems from O...\n",
       "                              ...                        \n",
       "9228    \\n\\nPrecisely, why not Cuba??  Why not???  The...\n",
       "9229    Your Custom Resume On Disk!\\n \\n              ...\n",
       "9230    Throughout the years of the Israel/Arab-Palest...\n",
       "9231    Does anyone know if there are any devices avai...\n",
       "9232    \\n\\n      Give ME a break, chum.  Are you tell...\n",
       "Name: text, Length: 9233, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLP6s2NzFI0I"
   },
   "source": [
    "위와 같이 text 내용을 보면 \\n, & 등 불필요한 문자가 들어가 있습니다.\n",
    "\n",
    "정규표현식을 이용해 이를 전처리하여 깔끔한 문장을 만들어 보도록 해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1648442940216,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "QdUm3Nyela3C"
   },
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def clean_text(texts): \n",
    "    corpus = [] \n",
    "    for i in range(0, len(texts)): \n",
    "\n",
    "        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"\\n\\]\\[\\>\\<]', '',texts[i]) #@%*=()/+ 와 같은 문장부호 제거\n",
    "        review = re.sub(r'\\d+','', review)#숫자 제거\n",
    "        review = review.lower() #소문자 변환\n",
    "        review = re.sub(r'\\s+', ' ', review) #extra space 제거\n",
    "        review = re.sub(r'<[^>]+>','',review) #Html tags 제거\n",
    "        review = re.sub(r'\\s+', ' ', review) #spaces 제거\n",
    "        review = re.sub(r\"^\\s+\", '', review) #space from start 제거\n",
    "        review = re.sub(r'\\s+$', '', review) #space from the end 제거\n",
    "        review = re.sub(r'_', ' ', review) #space from the end 제거\n",
    "        corpus.append(review) \n",
    "        \n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 4089,
     "status": "ok",
     "timestamp": 1648442944302,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "7DSTRxOwldRL",
    "outputId": "0d2b5a5d-b3e5-4d79-8728-1f67600b031d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text  target\n",
      "0        0  they were and even if washington might conside...      10\n",
      "1        1  we run spacenews views on our stareach bbs a l...      14\n",
      "2        2  not to worry the masons have been demonized an...      19\n",
      "3        3  only brendan mckay or maybe arf would come to ...      17\n",
      "4        4  help i am running some sample problems from or...       5\n",
      "...    ...                                                ...     ...\n",
      "9228  9228  precisely why not cuba why not the hatians are...      17\n",
      "9229  9229  your custom resume on disk macintosh or ibm co...       6\n",
      "9230  9230  throughout the years of the israelarabpalestin...      17\n",
      "9231  9231  does anyone know if there are any devices avai...       4\n",
      "9232  9232  give me a break chum are you telling me that c...      18\n",
      "\n",
      "[9233 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "temp = clean_text(train['text']) #메소드 적용\n",
    "train['text'] = temp\n",
    "print(train)\n",
    "\n",
    "temp = clean_text(test['text']) #test셋에서도 똑같은 전처리 과정을 해줍니다.\n",
    "test['text'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0chBUZqHlmAy"
   },
   "source": [
    "위의 데이터프레임과 같이 text가 깔끔히 정리되었습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9zPij2Nqmoqs"
   },
   "source": [
    "## 토큰화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsdDAwfgmrjI"
   },
   "source": [
    "토큰화(Tokenization)란 말뭉치(Corpus)를 주어진 단위(Token)로 나누는 과정을 의미합니다.\n",
    "\n",
    "따라서 다음과 같이 크게 두 종류로 구분해볼 수 있습니다.\n",
    "\n",
    "문장 토큰화\n",
    "단어 토큰화\n",
    "먼저 말뭉치를 문장 단위로 나누는 문장 토큰화(sentence tokenization)의 예시를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1648442944304,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "xp5kCRVflfDD"
   },
   "outputs": [],
   "source": [
    "text = \"Hello, nice to meet you. What's your name? Have a nice day! See you soon.\" # 예시 문장을 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8wHfahxm4Ak"
   },
   "source": [
    "영어에 대한 전처리는 대표적으로 nltk 패키지를 사용합니다.   \n",
    "이를 이용하기 위한 라이브러리를 다운받아 주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from os import path\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1648442949954,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "oh9H4U32m3Dw",
    "outputId": "c7939c16-0edb-4ceb-81bc-90ca9c4a69f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 토큰화 결과 ==> ['Hello, nice to meet you.', \"What's your name?\", 'Have a nice day!', 'See you soon.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print('문장 토큰화 결과 ==>',sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGZzzTObnl_v"
   },
   "source": [
    "따로 분리 기준으로 \"!\", \"?\", \".\" 등을 설정할 필요 없이 문장 단위로 말뭉치가 분리됩니다!\n",
    "\n",
    "다음으로 단어 단위로 나누는 단어 토큰화(word tokenization)의 예시를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1648442949955,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "6vsiviXlnh7b",
    "outputId": "b7bd3496-3e6d-4133-933c-8e2e57308cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 토큰화 결과 ==> ['Hello', ',', 'nice', 'to', 'meet', 'you', '.', 'What', \"'s\", 'your', 'name', '?', 'Have', 'a', 'nice', 'day', '!', 'See', 'you', 'soon', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print('단어 토큰화 결과 ==>', word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6b0UdlEnsHB"
   },
   "source": [
    "단어 단위로 깔끔하게 분리되네요. \"!\", \".\" 등의 구두점도 하나의 단어로 취급되는 것을 확인할 수 있습니다.\n",
    "\n",
    "이렇게 토큰화에 대해서 간단히 살펴보았습니다.\n",
    "\n",
    "그럼 뉴스 그룹 데이터에서도 같은 방법으로 토큰화를 진행시켜  \n",
    "'tokenized_stem' 열에 새로 토큰화 된 데이터를 생성해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 67896,
     "status": "ok",
     "timestamp": 1648443017833,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "I7_o2TDAnoCI",
    "outputId": "926bdfc1-ff57-490f-e4f1-0088383d719a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "      <td>10</td>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "      <td>14</td>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "      <td>19</td>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "      <td>17</td>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "      <td>5</td>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target  \\\n",
       "0   0  they were and even if washington might conside...      10   \n",
       "1   1  we run spacenews views on our stareach bbs a l...      14   \n",
       "2   2  not to worry the masons have been demonized an...      19   \n",
       "3   3  only brendan mckay or maybe arf would come to ...      17   \n",
       "4   4  help i am running some sample problems from or...       5   \n",
       "\n",
       "                                      tokenized_stem  \n",
       "0  they were and even if washington might conside...  \n",
       "1  we run spacenews views on our stareach bbs a l...  \n",
       "2  not to worry the masons have been demonized an...  \n",
       "3  only brendan mckay or maybe arf would come to ...  \n",
       "4  help i am running some sample problems from or...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = [] # 데이터프레임의 한 컬럼으로 추가할 리스트\n",
    "for sentence in train['text']: # 전처리된 리뷰들을 하나씩 꺼내옵니다\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tokenize = \" \".join(tokens) # tokens라는 리스트 안의 형태소들을 띄어쓰기로 분리된 하나의 문자열로 join시켜줍니다.\n",
    "    tokenized.append(tokenize) # 형태소 단위로 띄어쓰기된 문자열을 최종 리스트에 추가해줍니다\n",
    "train[\"tokenized_stem\"] = pd.DataFrame(tokenized) # 리스트를 데이터프레임으로 변환해 tokenized_stem라는 컬럼명으로 추가해줍니다.\n",
    "\n",
    "train.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCHu8rYAqFGF"
   },
   "source": [
    "## 품사 태깅(POS Tagging)\n",
    "\n",
    "자 이제 다음 단계인 품사 태깅에 대해 알아봅시다.\n",
    "\n",
    "품사 태깅이란 주어진 텍스트를 형태소 단위로 나눈 뒤, 각 형태소에 해당 품사를 태깅하여 리스트화 하는 것입니다.\n",
    "\n",
    "그럼 토큰화된 단어의 품사를 nltk의 pos_tag메소드를 이용하여 분리해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1648443017834,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "rt_QcYZSoo-0",
    "outputId": "41bf9fc7-8849-46f8-ac3d-1288265b41b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('help', 'NN'), ('i', 'VB'), ('am', 'VBP'), ('running', 'VBG'), ('some', 'DT'), ('sample', 'NN'), ('problems', 'NNS'), ('from', 'IN'), ('oreilly', 'RB'), ('volume', 'NN'), ('xt', 'JJ'), ('intrisics', 'NNS'), ('programming', 'VBG'), ('manual', 'JJ'), ('chapter', 'NN'), ('popupdialog', 'NN'), ('boxes', 'NNS'), ('and', 'CC'), ('so', 'RB'), ('onin', 'JJ'), ('example', 'NN'), ('page', 'NN'), ('creating', 'VBG'), ('a', 'DT'), ('popup', 'NN'), ('dialog', 'NN'), ('boxthe', 'JJ'), ('application', 'NN'), ('creates', 'VBZ'), ('window', 'VBP'), ('with', 'IN'), ('a', 'DT'), ('button', 'NN'), ('quit', 'NN'), ('and', 'CC'), ('press', 'NN'), ('methe', 'VBP'), ('button', 'NN'), ('press', 'NN'), ('me', 'PRP'), ('pops', 'VBZ'), ('up', 'RP'), ('a', 'DT'), ('dialog', 'NN'), ('box', 'IN'), ('the', 'DT'), ('strange', 'JJ'), ('feature', 'NN'), ('ofthis', 'JJ'), ('program', 'NN'), ('is', 'VBZ'), ('that', 'IN'), ('it', 'PRP'), ('always', 'RB'), ('pops', 'VBZ'), ('up', 'RP'), ('the', 'DT'), ('dialog', 'NN'), ('box', 'NN'), ('much', 'JJ'), ('faster', 'RBR'), ('thefirst', 'JJ'), ('time', 'NN'), ('if', 'IN'), ('i', 'JJ'), ('try', 'VBP'), ('to', 'TO'), ('pop', 'VB'), ('it', 'PRP'), ('up', 'RP'), ('a', 'DT'), ('nd', 'JJ'), ('time', 'NN'), ('rd', 'VB'), ('th', 'JJ'), ('time', 'NN'), ('it', 'PRP'), ('is', 'VBZ'), ('much', 'JJ'), ('slowerhas', 'IN'), ('anyone', 'NN'), ('any', 'DT'), ('experience', 'NN'), ('with', 'IN'), ('these', 'DT'), ('sample', 'JJ'), ('programs', 'NNS'), ('or', 'CC'), ('why', 'WRB'), ('i', 'JJ'), ('getthis', 'VBP'), ('behaviour', 'JJ'), ('fast', 'JJ'), ('response', 'NN'), ('time', 'NN'), ('for', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('time', 'NN'), ('but', 'CC'), ('slow', 'JJ'), ('responsetime', 'NN'), ('from', 'IN'), ('nd', 'JJ'), ('time', 'NN'), ('onwards', 'IN'), ('anyone', 'NN'), ('can', 'MD'), ('give', 'VB'), ('me', 'PRP'), ('some', 'DT'), ('ideas', 'NNS'), ('on', 'IN'), ('how', 'WRB'), ('to', 'TO'), ('program', 'NN'), ('popups', 'NNS'), ('so', 'RB'), ('that', 'IN'), ('each', 'DT'), ('timethey', 'NN'), ('popup', 'VBP'), ('in', 'IN'), ('reasonable', 'JJ'), ('fast', 'JJ'), ('response', 'NN'), ('time', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# pos_tag()의 입력값으로는 단어의 리스트가 들어가야 한다.\n",
    "print(nltk.pos_tag(nltk.word_tokenize(train['text'][4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G28eZBrurGfG"
   },
   "source": [
    "품사 태깅은 꼭 필요한 품사(ex. 명사, 동사)를 추출할 때 유용하게 쓰일 수 있습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-QifldUSweF"
   },
   "source": [
    "뉴스 텍스트는 명사만으로 그룹 분류를 판단하기 어렵기 때문에\n",
    "\n",
    "우선 임의로 명사, 동사, 형용사, 부사를 추출하여 사용해보겠습니다. (판단에 따라 설정해주세요 !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 150568,
     "status": "ok",
     "timestamp": 1648443168394,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "SHF5iNclv1x_",
    "outputId": "74875ff9-d2e9-450e-a894-95b526a91d49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized_stem</th>\n",
       "      <th>main_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "      <td>10</td>\n",
       "      <td>they were and even if washington might conside...</td>\n",
       "      <td>were even washington consider patty bust id tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "      <td>14</td>\n",
       "      <td>we run spacenews views on our stareach bbs a l...</td>\n",
       "      <td>run spacenews views stareach bbs localoperatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "      <td>19</td>\n",
       "      <td>not to worry the masons have been demonized an...</td>\n",
       "      <td>not worry masons have been demonized harrassed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "      <td>17</td>\n",
       "      <td>only brendan mckay or maybe arf would come to ...</td>\n",
       "      <td>only brendan mckay maybe arf come rescue nazir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "      <td>5</td>\n",
       "      <td>help i am running some sample problems from or...</td>\n",
       "      <td>help i am running sample problems oreilly volu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  target  \\\n",
       "0   0  they were and even if washington might conside...      10   \n",
       "1   1  we run spacenews views on our stareach bbs a l...      14   \n",
       "2   2  not to worry the masons have been demonized an...      19   \n",
       "3   3  only brendan mckay or maybe arf would come to ...      17   \n",
       "4   4  help i am running some sample problems from or...       5   \n",
       "\n",
       "                                      tokenized_stem  \\\n",
       "0  they were and even if washington might conside...   \n",
       "1  we run spacenews views on our stareach bbs a l...   \n",
       "2  not to worry the masons have been demonized an...   \n",
       "3  only brendan mckay or maybe arf would come to ...   \n",
       "4  help i am running some sample problems from or...   \n",
       "\n",
       "                                            main_pos  \n",
       "0  were even washington consider patty bust id tr...  \n",
       "1  run spacenews views stareach bbs localoperatio...  \n",
       "2  not worry masons have been demonized harrassed...  \n",
       "3  only brendan mckay maybe arf come rescue nazir...  \n",
       "4  help i am running sample problems oreilly volu...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def postagging(dataframe):\n",
    "    main_pos = [] # 데이터프레임의 새 컬럼이 될 리스트\n",
    "    for sentence in dataframe['text']: # 리뷰들을 하나씩 가져옵니다\n",
    "        pos = nltk.pos_tag(nltk.word_tokenize(sentence)) # 형태소 분석을 진행하고 해당 리스트를 pos라는 변수로 받습니다\n",
    "        main_words = [word_pos[0] for word_pos in pos if word_pos[1] in ('JJ', 'JJR', 'JJS', #형용사\n",
    "                                                                         'NN', 'NNS', 'NNP', 'NNPS', #명사\n",
    "                                                                         'RB', 'RBR', 'RBBS', #부사\n",
    "                                                                         'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ' #동사\n",
    "                                                                         )] # 가져오고자 하는 품사에 해당하면 해당 형태소를 main_words 리스트에 추가합니다.\n",
    "        main_words_str = \" \".join(main_words) # main_words 리스트 안의 형태소들을 띄어쓰기로 분리된 하나의 문자열로 join시켜줍니다.\n",
    "        main_pos.append(main_words_str) # 선택한 형태소들로 이루어진 문자열을 최종 리스트에 추가해줍니다\n",
    "        dataframe[\"main_pos\"] = pd.DataFrame(main_pos) # 리스트를 데이터프레임으로 변환해 main_pos라는 컬럼명으로 추가해줍니다.\n",
    "\n",
    "postagging(train)\n",
    "postagging(test) ## test셋도 똑같이 품사태깅을 적용해줍니다.\n",
    "train.head() # 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-cjSZ9RTMc-",
    "tags": []
   },
   "source": [
    "자 이제 총 두 개의 전처리된 컬럼이 생성되었습니다!\n",
    "\n",
    "어떤 전처리 과정이 성능이 가장 잘 나올지는 미지수입니다. 직접 다양한 시도를 통해 최적의 전처리 프로세스를 찾아보세요!\n",
    "\n",
    "이번 베이스라인에서는 마지막에 생성한 main_pos 컬럼을 이용해 모델 학습을 진행하겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hxhf8OlSTcTD"
   },
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi13gJY0TiC3"
   },
   "source": [
    "## train.csv 학습/검증셋 분리하기\n",
    "\n",
    "모델링 후 성능을 검증하기 위해 학습셋과 검증셋으로 train 데이터를 나누어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1648443168397,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "ihyOU0ERTodN"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = train.copy()\n",
    "train, val = train_test_split(data)\n",
    "train.reset_index(inplace=True) # 전처리 과정에서 데이터가 뒤섞이지 않도록 인덱스를 초기화해주었습니다.\n",
    "val.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1648443168399,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "1cRcuEcOT8Oe",
    "outputId": "3e178c7f-d9c8-407c-d256-2dbf3af4ba81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 셋 모양 : (6924, 6)\n",
      "val 데이터 셋 모양 : (2309, 6)\n"
     ]
    }
   ],
   "source": [
    "print( 'train 데이터 셋 모양 :', train.shape)\n",
    "print( 'val 데이터 셋 모양 :', val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vbLThgdUMvw"
   },
   "source": [
    "train 셋은 6924개, val 셋은 2309개 데이터로 나뉘어 진 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTby2_4tTV-3"
   },
   "source": [
    "## 벡터화\n",
    "\n",
    "CountVectorizer를 사용하였습니다.\n",
    "\n",
    "이 부분에 대한 설명은 [첫번째 베이스라인](https://dacon.io/competitions/official/235884/codeshare/4738?page=1&dtype=recent)에 자세히 나와있으니 참고 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1648443168401,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "_3e5aN-nyJZl"
   },
   "outputs": [],
   "source": [
    "X_train = train.main_pos #training 데이터에서 문서 추출\n",
    "y_train = train.target #training 데이터에서 라벨 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1853,
     "status": "ok",
     "timestamp": 1648443170238,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "5cHPWRJEUYbU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer() #countvectorizer 생성\n",
    "vectorizer.fit(X_train) # countvectorizer 학습\n",
    "X_train_vec = vectorizer.transform(X_train) # transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ias3N3yfW70Q"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82318,
     "status": "ok",
     "timestamp": 1648443252548,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "2eXcsVLxUaAe",
    "outputId": "5467c5fd-365a-46ff-fb19-bc5aa5f60d7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression #모델 불러오기\n",
    "model = LogisticRegression(max_iter=500) #객체에 모델 할당\n",
    "model.fit(X_train_vec, y_train) #모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74kftNbTb-LB"
   },
   "source": [
    "## 검증셋으로 모델 성능 검증\n",
    "\n",
    "트레인 셋에서 학습된 모델을   \n",
    "검증 셋을 통해서 얼마나 성능이 나오는지 확인해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1648443252550,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "c7cEr76mW66D"
   },
   "outputs": [],
   "source": [
    "X_val = val.main_pos #validation 데이터에서 전처리된 문서 추출\n",
    "y_val = val.target #validation 데이터에서 라벨 추출\n",
    "\n",
    "X_val_vec = vectorizer.transform(X_val) # train셋으로 fit한 벡터라이저 이용해 transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1648443252551,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "1Y3sTTCVXqA9",
    "outputId": "1273675b-6f67-4a58-e533-f0de242a83f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 16  2 ... 19  3  7]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val_vec)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1648443252552,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "YS8N-JDVXwZF",
    "outputId": "051d6023-e796-4874-cad4-238848f9fcd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 의 예측 정확도는 0.605\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Logistic Regression 의 예측 정확도는', round(metrics.accuracy_score(y_val, y_pred),3)) # 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EWl3HSqcJLr"
   },
   "source": [
    "검증 셋을 예측해본 결과 0.605의 정확도를 얻었습니다!\n",
    "\n",
    "조금 더 성능을 끌어 올려보는 작업을 해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DntLmgOKY-2k"
   },
   "source": [
    "# TF-IDF\n",
    "\n",
    "Tf-Idf (Term Frequency - Inverse Document Frequency)는 \n",
    "\n",
    "TF(단어 빈도, term frequency) : 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값  \n",
    "IDF(역문서 빈도, inverse document frequency) : 단어 자체가 문서군 내에서 자주 사용하여 얼마나 그 단어가 흔하게 등장하는지를 나타내는 값의 역수   \n",
    "를 곱한 값입니다.\n",
    "\n",
    "즉, 특정 문서 내에서 단어 빈도가 높을 수록, 그리고 전체 문서들 중 그 단어를 포함한 문서가 적을 수록 TF-IDF값이 높아집니다.\n",
    "\n",
    "특정 단어를 포함하는 문서들이 많을 수록 로그 함수 안의 값이 1에 가까워지게 되고,   \n",
    "이 경우 IDF값과 TF-IDF값은 0에 가까워지게 되는 것입니다.\n",
    "\n",
    "따라서 이 값을 이용하면 모든 문서에 흔하게 나타나는 단어를 걸러내는 효과를 얻을 수 있습니다. \n",
    "\n",
    "TF-IDF는 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업,  \n",
    " 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰입니다.\n",
    "\n",
    "그럼, TF-IDF를 활용해 문장 벡터를 만들기 위한   \n",
    "TfidfVectorizer 을 적용하여 모델의 성능을 높여보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32535,
     "status": "ok",
     "timestamp": 1648443285074,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "Epr-sI9VXyKf",
    "outputId": "ff0e5521-df4a-44ad-8396-c0e29638d43e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 & 테스트 데이터 Text의 TfidfVectorizer Shape: (6924, 630692) (2309, 630692)\n",
      "TF-IDF Logistic Regression 의 예측 정확도는 0.712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train = train.main_pos #training 데이터에서 문서 추출\n",
    "y_train = train.target #training 데이터에서 라벨 추출\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환. \n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), max_df=300)\n",
    "tfidf_vect.fit(X_train)\n",
    "\n",
    "X_val = val.main_pos #validation 데이터에서 전처리된 문서 추출\n",
    "y_val = val.target #validation 데이터에서 라벨 추출\n",
    "\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_val_tfidf_vect = tfidf_vect.transform(X_val) # train셋으로 fit한 벡터라이저 이용해 transform\n",
    "print('학습 & 테스트 데이터 Text의 TfidfVectorizer Shape:',X_train_tfidf_vect.shape, X_val_tfidf_vect.shape)\n",
    "\n",
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression(solver='liblinear', C = 10) \n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)\n",
    "pred = lr_clf.predict(X_val_tfidf_vect)\n",
    "print('TF-IDF Logistic Regression 의 예측 정확도는 {0:.3f}'.format(metrics.accuracy_score(y_val ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ik2AHKgnhsQT"
   },
   "source": [
    "TF-IDF를 적용하여 검증 셋을 예측해본 결과 0.712의 정확도로 무려 0.107 이나 올랐군요 !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRisTfV8iI8P",
    "tags": []
   },
   "source": [
    "## test.csv 분류하기\n",
    "\n",
    "\n",
    "이제 본격적으로 대회에서 주어진 정답이 없는 test 데이터의 라벨을 예측해보겠습니다.\n",
    "\n",
    "그럼, 트레인 셋과 검증 셋으로 나누어 성능을 확인해 준 것을 하나의 트레인 셋으로 통합하여\n",
    "\n",
    "다시 모델을 만들어주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30340,
     "status": "ok",
     "timestamp": 1648443435899,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "xf2SaX-S2P5P",
    "outputId": "bffdafc2-22ad-42bc-998c-5d8d8cfad60a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, solver='liblinear')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data.main_pos #전체 training 데이터에서 문서 추출\n",
    "y_train = data.target #전체 training 데이터에서 라벨 추출\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환. \n",
    "tfidf_vect = TfidfVectorizer(ngram_range=(1,2), max_df=300)\n",
    "tfidf_vect.fit(X_train)\n",
    "\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "\n",
    "# LogisticRegression을 이용하여 학습/예측/평가 수행. \n",
    "lr_clf = LogisticRegression(solver='liblinear', C = 10) \n",
    "lr_clf.fit(X_train_tfidf_vect , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zjx9Hdt2X6p"
   },
   "source": [
    "이제 test셋을 모델에 넣어 예측값을 만들어 줍니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2067,
     "status": "ok",
     "timestamp": 1648443437923,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "rd6Pma-FzKz1",
    "outputId": "c5f180ec-44d9-4491-f421-f74bf5e8d0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 16 11 ...  4  1 12]\n"
     ]
    }
   ],
   "source": [
    "X_test = test.main_pos\n",
    "X_test_vec = tfidf_vect.transform(X_test)\n",
    "pred_test = lr_clf.predict(X_test_vec)\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-96pRuKz2vK"
   },
   "source": [
    "## dacon 대회에 제출하기\n",
    "\n",
    "이제 예측한 결과를 submission.csv 파일로 만들어서 대회 페이지에 제출해보도록 합시다.\n",
    "\n",
    "제출한 뒤 리더보드를 통해 결과를 확인합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1648443437924,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "P4XnPzXqzjPR",
    "outputId": "6a9607fa-4cfc-4688-87a2-889601426054"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   1       0\n",
       "2   2       0\n",
       "3   3       0\n",
       "4   4       0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제출용 sample 파일을 불러옵니다.\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1648443437925,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "TfNcJu1A0E-w",
    "outputId": "67bbfdcd-3914-4801-a797-b5af71088cc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>9228</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>9229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>9230</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>9231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>9232</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target\n",
       "0        0       3\n",
       "1        1      16\n",
       "2        2      11\n",
       "3        3       8\n",
       "4        4      13\n",
       "...    ...     ...\n",
       "9228  9228      16\n",
       "9229  9229       1\n",
       "9230  9230       4\n",
       "9231  9231       1\n",
       "9232  9232      12\n",
       "\n",
       "[9233 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 구한 예측값을 그대로 넣어줍니다.\n",
    "submission['target'] = pred_test\n",
    "\n",
    "# 데이터가 잘 들어갔는지 확인합니다.\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3Rfv8OQ7q5X"
   },
   "source": [
    "submission을 csv 파일로 저장합니다.   \n",
    "index=False란 추가적인 id를 부여할 필요가 없다는 뜻입니다.    \n",
    "정확한 채점을 위해 꼭 index=False를 넣어주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1648443437925,
     "user": {
      "displayName": "World Papa",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "02589349459586782651"
     },
     "user_tz": -540
    },
    "id": "aGtUiaue0JCZ"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_baseline2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONaooqtP0NOO"
   },
   "source": [
    "이렇게 생성된 submission.csv 파일을 데이콘 대회 페이지에 업로드 & 제출하여 결과를 확인해보세요!\n",
    "\n",
    "문제를 해결하기 위한 여러분의 방법을 코드 공유 게시판에 공유해주세요\n",
    "\n",
    "좋아요와 댓글을 합산하여 가장 높은 점수를 얻으신 분께 데이콘 후드가 제공됩니다!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPp43xsqEcyg7EyS80nkUjA",
   "collapsed_sections": [],
   "name": "news_basline2_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
