{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d773d194-9dbb-4306-8d42-995607603ddd",
   "metadata": {},
   "source": [
    "# 12 비정형_Audio\n",
    "# 1. 분석 환경 준비\n",
    "## 1.1. 데이터 불러오기\n",
    "분석하려는 데이터를 가져오는 작업\n",
    "\n",
    "* 파이썬 라이브러리 Pandas 이용\n",
    "\n",
    "* glob() 메소드 이용하여 특정한 패턴이나 확장자를 가진 파일들의 경로나 이름을 리스트 형식으로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e6faa-7598-4ccf-b4bc-2f9b845a805a",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리\n",
    "## 2.1. WAV 파일 전처리\n",
    "\n",
    "* librosa.load를 통해 wav 파일의 signal과 sample rate(일정한 시간 간격) 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed7c82-ba8e-4c89-ba58-873365b85ae5",
   "metadata": {},
   "source": [
    "## 2.2. 음성 길이 설정\n",
    "\n",
    "음성 중 길이가 가장 작은 길이의 데이터를 기준으로 데이터를 잘라서 같은 길이로 설정\n",
    "\n",
    "* pad2d() 메소드 사용\n",
    "* 혹은 직접 음성 데이터 자르기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725da2a-1e30-4b2d-b3b7-39b74051e209",
   "metadata": {},
   "source": [
    "## 2.3. 음성 데이터 특징 추출\n",
    "\n",
    "입력된 신호에서 노이즈 및 배경 소리로 부터 실제로 유용한 소리의 특징을 추출\n",
    "\n",
    "### 2.3.1. Mel Spectrogram   \n",
    "낮은 주파수를 높은 주파수보다 더 예민하게 받아들이므로 이 주파수를 mel scale로 볼 수 있게 하는 음성의 특징 추출 방법\n",
    "\n",
    "* 음성 데이터를 raw data를 그대로 사용하면 파라미터가 너무 많아지기도 하고 데이터 용량이 너무 커지므로 mel spectrogram을 사용\n",
    "* mel_spectrogram() 메소드 이용\n",
    "    * 1. n_fft : 한 번 fft(Fast Fouriter Transform)를 해 줄 만큼의 sequence 길이 (음성의 길이를 얼마만큼으로 자를 것인가 = window)\n",
    "    * 2. hop_length : window 간의 거리 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4de8f1-9e8e-47dc-ab55-a41107b3904a",
   "metadata": {},
   "source": [
    "### 2.3.2. MFCC (Mel-frequency cepstral coefficients)\n",
    "\n",
    "입력된 소리 전체를 대상으로 하는 것이 아니라, 일정 구간(Short time)식 나누어 이 구간에 대한 스펙트럼을 분석하여 특징 추출\n",
    "\n",
    "* librosa.feature.mfcc(wav) 메소드 이용\n",
    "    *  sr : sampling rate\n",
    "    * n_mfcc :  return 될 mfcc의 개수를 정해주는 파라미터. 더 다양한 데이터 특징을 추출하기 위해서 증가 시킴\n",
    "    * n_fft : frame의 length를 결정하는 파라미터. n_fft를 설정하면 window size가 자동으로 같은 값으로 설정. n_fft는 window size보다 크거나 같아야 함   \n",
    "        일반적으로 자연어 처리에서는 음성을 25m의 크기를 기본으로 하고 있음   \n",
    "        (ex. 16000Hz인 음성에서는 400에 해당하는 값 (16000 * 0.025 = 400) 즉, n_fft는 sr에 frame_length인 0.025를 곱한 값)\n",
    "    * hop_length : 길이만큼 옆으로 가면서 데이터를 읽습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6965f2-5c17-48df-9113-14432e517a73",
   "metadata": {},
   "source": [
    "## 2.4. 스케일링\n",
    "\n",
    "음성 데이터에서 추출한 특징을 전처리 scaling\n",
    "\n",
    "* 직접 : (mel - mel.mean()) / mel.std() \n",
    "* 메소드 사용 : sklearn.preprocessing.scale(mfcc, axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27ba70-8a66-400a-a028-79adcb76a883",
   "metadata": {},
   "source": [
    "## 2.5. 시각화\n",
    "\n",
    "특징 추출된 음성 데이터의 시각적인 특징을 보기 위하여 시각화\n",
    "\n",
    "*  librosa 라이브러리의 specshow() 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7d70e-6e27-42ee-8a2f-e9d9cfa10c43",
   "metadata": {},
   "source": [
    "## 2.6. 데이터 차원 확대 \n",
    "\n",
    "딥러닝 모델에 넣기 위하여 데이터 차원 확대\n",
    "\n",
    "* 방법 1 : np.expand_dims(train_mfccs, -1)\n",
    "* 방법 2 : train_x.reshape(-1, train_x.shape[1], train_x.shape[2], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80486e73-7a5b-4a57-97f9-6948d1bfea5a",
   "metadata": {},
   "source": [
    "# 3. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ca4c4-caaf-4bc1-abab-16aba7c8dd71",
   "metadata": {},
   "source": [
    "## 3.1. 변수 정의\n",
    "\n",
    "X : 독립 변수 (음성 데이터)   \n",
    "y : 종속 변수 (라벨 ,타겟)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3068e-fc10-4796-aef7-a8e31351ebaa",
   "metadata": {},
   "source": [
    "## 3.2. CNN\n",
    "Convolution이라는 전처리 작업이 들어가는 Neural Network 모델\n",
    "\n",
    "* 음성 데이터에서도 CNN 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d6caae-b6f8-4c09-842e-0b526a1a4f5d",
   "metadata": {},
   "source": [
    "### 3.2.1. CNN 모델 설계\n",
    "\n",
    "keras.Sequential\n",
    "\n",
    "* Conv2D :  이미지의 특징(feature map)을 추출해내는 역할\n",
    "    \n",
    "    * Stride : 커널을 이동시키는 거리\n",
    "    * Padding : 이미지 주위에 0을 둘러서 이미지 데이터의 축소를 방지\n",
    "    * activation : 활성화 함수 설정\n",
    "    \n",
    "* MaxPooling2D : 데이터의 공간적 크기를 축소하는데 사용\n",
    "* Dropout : 뉴럴 네트워크의 유닛(뉴런)들을 랜덤으로 비활성화 하여 과적합(Overfittng)을 방지\n",
    "* Flatten : N차원 배열을 1차원으로 변환\n",
    "* Dense : 1차원 배열을 뉴럴넷에 입력 (오로지 퍼셉트론으로 이루어짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68660272-ad73-4efd-92e8-ee59fb81fa1d",
   "metadata": {},
   "source": [
    "### 3.2.2. 모델 컴파일\n",
    "\n",
    "model.complie   \n",
    "생성 모델과 학습 알고리즘(옵티마이저)을 붙이기 위하여 학습할 수 있는 상태로 만들어 주도록 컴파일\n",
    "\n",
    "* optimizer : 최적화 방법 \n",
    "* loss : 손실함수, 회귀의 경우 mse, 분류일 경우 categorical_crossentropy\n",
    "* metrix : 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec6b6c-54f9-4d41-9dc7-05bf7e167491",
   "metadata": {},
   "source": [
    "### 3.2.3. 모델 학습\n",
    "\n",
    "history = model.fit\n",
    "\n",
    "* 모델을 history 라는 매개변수에 저장하게 되면 모델에서 학습했던 자취들이 남아있도록 함\n",
    "* epochs : 에포크\n",
    "* validation_split : 모델 검증\n",
    "* batch_size : 배치사이즈\n",
    "* callbacks : 콜백함수 사용\n",
    "    * EarlyStopping : 모델 성능 향상이 없는 경우 학습을 중지\n",
    "    * ModelCheckpoint : 가장 validation performance 가 좋은 모델을 저장\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9144de-1617-4362-8998-cf6260b68bff",
   "metadata": {},
   "source": [
    "# 4. 모델 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c9523-332a-4b03-aacf-efd31c7d5533",
   "metadata": {},
   "source": [
    "## 4.1. 분류 모델 지표\n",
    "### 4.1.1. Accuracy\n",
    "올바르게 예측된 데이터의 수를 전체 데이터의 수로 나눈 값\n",
    "\n",
    "### 4.1.2. F1-score\n",
    "정밀도와 재현율의 조화 평균\n",
    "\n",
    "precision과 recall이 0 에 가까울수록 F1 score도 동일하게 낮은 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acade86e-ff7b-49e2-ba08-fc6e7ad36343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesang",
   "language": "python",
   "name": "sesang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
