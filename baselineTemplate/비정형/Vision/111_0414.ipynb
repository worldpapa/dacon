{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ce4e57-4a65-4885-b89c-efb39eba1960",
   "metadata": {},
   "source": [
    "# 11 비정형_CV\n",
    "\n",
    "# 1. 분석 환경 준비\n",
    "## 1.1. 데이터 불러오기\n",
    "분석하려는 데이터를 가져오는 작업\n",
    "\n",
    "* 파이썬 라이브러리 Pandas 이용\n",
    "\n",
    "* Image.open() 메소드 이용\n",
    "\n",
    "* glob() 메소드 이용하여 특정한 패턴이나 확장자를 가진 파일들의 경로나 이름을 리스트 형식으로 반환\n",
    "\n",
    "* Imread() 메소드로 이미지 로드 (이미지를 넘파이 배열(행렬)로 변환)\n",
    "\n",
    "* imshow() 메소드로 이미지 확인\n",
    "\n",
    "* imwrite() 메소드로 전처리를 위한 이미지 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770273d-82b1-49b3-8c50-e870645d908f",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a295e-794b-4786-a61e-69c51d51d071",
   "metadata": {},
   "source": [
    "## 2.1. 이미지 크기 변경 Resize\n",
    "\n",
    "이미지들은 제각기 다양한 크기를 가지며, 특성으로 사용하려면 동일한 차원\n",
    "\n",
    "\n",
    "* resize(image, (32, 32)) 메소드 이용\n",
    "* 머신러닝에서 많이 사용하는 이미지 크기는 32X32 ,64X64 ,96X96 ,245X256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff8138c-fa42-4877-99c2-f442435263fe",
   "metadata": {},
   "source": [
    "## 2.2. 이미지 자르기 Crop\n",
    "\n",
    "이미지 주변을 제거하여 차원을 줄임. \n",
    "\n",
    "* 이미지는 2차원 넘파이 배열로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b393d7f-ddc2-4b3f-94dd-8a992bbe5bfd",
   "metadata": {},
   "source": [
    "## 2.3. 이미지 투명도 처리\n",
    "\n",
    " 각 픽셀을 주변 픽셀의 평균값으로 변환\n",
    " \n",
    "* blur(image, (5,5)) : 각 픽셀 주변의 5X5커널 평균값으로 이미지를 흐리게 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cca5022-da31-45f3-aef5-e3093abc9f4a",
   "metadata": {},
   "source": [
    "## 2.4. 이미지 선명도\n",
    "\n",
    "중앙 픽셀을 부각하는 커널을 만들면 이미지의 경계선에서 대비가 더욱 두드러지는 효과\n",
    "\n",
    "* 대상 픽셀을 강조하는 커널을 만듦   \n",
    "\n",
    "\n",
    "kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])\n",
    "\n",
    "* filter2D(image, -1, kernel)로 이미지에 커널을 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a79851-2700-4aa0-8ee4-97547aea19e5",
   "metadata": {},
   "source": [
    "## 2.5. 이미지 대비\n",
    "\n",
    "히스토그램 평활화는 객체의 형태가 두드러지도록 만들어주는 이미지 처리 도구\n",
    "\n",
    "* 히스토그램 평활화는 픽셀값의 범위가 커지도록 이미지를 변환\n",
    "* 히스토그램 평활화는 관심 대상을 다른 객체나 배경과 잘 구분 시킴\n",
    "* equalizeHist(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2687e110-ea6a-4a2c-bfbb-a404726b0975",
   "metadata": {},
   "source": [
    "## 2.6. 색상 구분\n",
    "\n",
    "한 색상을 구분하려면 색 범위를 정의하고 이미지에 마스크를 적용\n",
    "* 이미지를 HSV(색상, 채도, 명도)로 변환 -> 격리시킬 값의 범위를 정의 -> 이미지에 적용할 마스크를 만듦 (마스크의 흰색 영역만 유지)\n",
    "* cvtColor(image_bgr, cv2.COLOR_BGR2HSV) # BGR에서 HSV로 변환\n",
    "* inRange(image_hsv, lower_blue, upper_blue) # 마스크를 만듦\n",
    "* bitwise_and(image_bgr, image_bgr, mask=mask) # 이미지에 마스크를 적용\n",
    "* cvtColor(image_bgr_masked, cv2.COLOR_BGR2RGB) # BGR에서 RGB로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175c5c6c-95d0-4097-9f3d-f95756c96e01",
   "metadata": {},
   "source": [
    "## 2.7. 이미지 이진화(임계처리) thresholding\n",
    "어떤 값보다 큰 값을 가진 픽셀을 흰색으로 만들고 작은 값을 가진 픽셀은\n",
    "검은색으로 만드는 과정\n",
    "\n",
    "* adaptive thresholding은 픽셀의 임계값이 주변 픽셀의 강도에 의해 결정\n",
    "* 이미지 안의 영역 마다 빛 조건이 달라질 때 유용함\n",
    "* adaptiveThreshold() 메소드 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb3d087-aa1a-4571-b7c1-784d8a17485b",
   "metadata": {},
   "source": [
    "## 2.8. 배경 제거\n",
    "\n",
    "이미지의 전경만 분리해내려면 원하는 전경 주위에 사각형 박스를 그리고 그랩컷 알고리즘 실행    \n",
    "그랩컷은 사각형 밖에 있는 모든 것이 배경이라고 가정하고 이 정보를 사용하여 사각형 안에 있는 배경을 찾음\n",
    "\n",
    "* 검은색 영역은 배경이라고 확실하게 가정한 사각형의 바깥쪽 영역\n",
    "* 회색 영역은 그랩컷이 배경이라고 생각하는 영역\n",
    "* 흰색 영역은 전경\n",
    "* grabCut() 메소드 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c9fa1-49c0-4fa9-80e3-aef5f7da27ff",
   "metadata": {},
   "source": [
    "## 2.9. 경계선 감지\n",
    "\n",
    "경계선 감지는 컴퓨터 비전의 주요 관심 대상이며 경계선은 많은 정보가 담긴 영역   \n",
    "정보가 적은 영역을 제거하고 대부분의 정보가 담긴 이미지 영역을 구분\n",
    "\n",
    "* Canny() 메소드 이용하여 캐니 경계선 감지기 적용\n",
    "* 그레이디언트 임계값의 저점과 고점을 나타내는 두 매개변수가 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b39104-9274-44a1-9b41-ded1f3daed42",
   "metadata": {},
   "source": [
    "## 2.10. 모서리 감지\n",
    "\n",
    "모서리는 정보가 많은 포인트로, 두 개의 경계선이 교차하는 지점을 감지하는 방법\n",
    "\n",
    "  \n",
    "* cornerHarris() 메소드 이용하여 해리스 모서리 감지기 사용   \n",
    "윈도(이웃, 패치)안의 픽셀이 작은 움직임에도 크게 변하는 윈도를 찾음\n",
    "    * block_size : 각 픽셀에서 모서리 감지에 사용되는 이웃 픽셀 크기\n",
    "    * aperture : 사용하는 소벨 커널 크기\n",
    "* dilate() 메소드 이용하여 모서리 표시를 부각"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b2dd70-e0f0-4c2f-86ac-a4b9cb5cb754",
   "metadata": {},
   "source": [
    "## 2.11. 이미지 1차원 샘플\n",
    "\n",
    "이미지를 머신러닝에 필요한 샘플로 변환하기 위하여 이미지 데이터가 담긴 다차원 배열을 샘플값이 담긴 벡터로 변환\n",
    "\n",
    "* image.Flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55c2010-f008-4cd3-ba0c-0891a50b8633",
   "metadata": {},
   "source": [
    "## 2.11. 라벨 인코딩 Label Encoding\n",
    "범주(카테고리)형 데이터 존재 시 문자열을 수치형으로 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c479a-afe0-484e-aadc-628288ebd977",
   "metadata": {},
   "source": [
    "## 2.12. 정규화 Normalization\n",
    "\n",
    "이미지의 RGB 채널은 각각 0~255까지의 값을 갖고 있기 때문에 255로 나누어 0에서 1 사이 값을 갖도록 정규화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6590c5f-bea4-4ac1-bfc0-f2c500bc1b29",
   "metadata": {},
   "source": [
    "# 3. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7cdbc-7a0c-4395-8ab2-53f55d19a898",
   "metadata": {},
   "source": [
    "## 3.1. 변수 정의\n",
    "\n",
    "X : 독립 변수 (이미지 데이터)   \n",
    "y : 종속 변수 (라벨, 타겟)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161abaa-a726-45d2-9891-d8e95082f338",
   "metadata": {},
   "source": [
    "## 3.2 CNN\n",
    "Convolution이라는 전처리 작업이 들어가는 Neural Network 모델\n",
    "\n",
    "* 딥러닝에서 주로 이미지나 영상 데이터를 처리할 때 쓰임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575cfbbc-4284-4f72-898c-fd2cdd55c632",
   "metadata": {},
   "source": [
    "### 3.2.1. CNN 모델 설계\n",
    "\n",
    "keras.Sequential\n",
    "\n",
    "* Conv2D :  이미지의 특징(feature map)을 추출해내는 역할\n",
    "    \n",
    "    * Stride : 커널을 이동시키는 거리\n",
    "    * Padding : 이미지 주위에 0을 둘러서 이미지 데이터의 축소를 방지\n",
    "    * activation : 활성화 함수 설정\n",
    "    \n",
    "* MaxPooling2D : 데이터의 공간적 크기를 축소하는데 사용\n",
    "* Dropout : 뉴럴 네트워크의 유닛(뉴런)들을 랜덤으로 비활성화 하여 과적합(Overfittng)을 방지\n",
    "* Flatten : N차원 배열을 1차원으로 변환\n",
    "* Dense : 1차원 배열을 뉴럴넷에 입력 (오로지 퍼셉트론으로 이루어짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b15c5-6f6a-4807-befa-7cb258dae5ae",
   "metadata": {},
   "source": [
    "### 3.2.2. 모델 컴파일\n",
    "\n",
    "model.complie   \n",
    "생성 모델과 학습 알고리즘(옵티마이저)을 붙이기 위하여 학습할 수 있는 상태로 만들어 주도록 컴파일\n",
    "\n",
    "* optimizer : 최적화 방법 \n",
    "* loss : 손실함수, 회귀의 경우 mse, 분류일 경우 categorical_crossentropy\n",
    "* metrix : 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d65b04-045d-46af-9aeb-3c13b63f4225",
   "metadata": {},
   "source": [
    "### 3.2.3. 모델 학습\n",
    "\n",
    "history = model.fit\n",
    "\n",
    "* 모델을 history 라는 매개변수에 저장하게 되면 모델에서 학습했던 자취들이 남아있도록 함\n",
    "* epochs : 에포크\n",
    "* validation_split : 모델 검증\n",
    "* batch_size : 배치사이즈\n",
    "* callbacks : 콜백함수 사용\n",
    "    * EarlyStopping : 모델 성능 향상이 없는 경우 학습을 중지\n",
    "    * ModelCheckpoint : 가장 validation performance 가 좋은 모델을 저장\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb41d58-0d25-4771-8413-be84be3e9568",
   "metadata": {},
   "source": [
    "# 4. 모델 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b70f5-5803-4e62-88fe-14bb90af77be",
   "metadata": {},
   "source": [
    "## 4.1. 회귀모델 지표\n",
    "\n",
    "### 4.1.1. MSE\n",
    "예측값과 실제값의 차이인 오차들의 제곱 평균\n",
    "\n",
    "회귀 모델의 주요 손실함수\n",
    "### 4.1.2. RMSE\n",
    "MSE에 root를 씌운 값\n",
    "\n",
    "오류 지표를 실제 값과 유사한 단위로 다시 변환하기에 해석이 다소 용이\n",
    "### 4.1.3. MAE\n",
    "실제값과 예측값의 차이인 오차들의 절댓값 평균\n",
    "\n",
    "MSE보다는 특이치에 덜 민감\n",
    "### 4.1.4. NMAE\n",
    "정규화된 MAE\n",
    "\n",
    "척도가 다른 데이터 세트의 MAE 비교할 때 용이\n",
    "\n",
    "NMAE가 0.1이라면 10%정도 틀렸다고 해석 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a85b8-9d84-417a-a227-34b7191114d1",
   "metadata": {},
   "source": [
    "## 4.2. 분류 모델 지표\n",
    "### 4.2.1. Accuracy\n",
    "올바르게 예측된 데이터의 수를 전체 데이터의 수로 나눈 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6d84f-30d2-47aa-8ff3-12b44d713759",
   "metadata": {},
   "source": [
    "### 4.2.2. F1-score\n",
    "\n",
    "정밀도와 재현율의 조화 평균\n",
    "\n",
    "* precision과 recall이 0 에 가까울수록 F1 score도 동일하게 낮은 값"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world",
   "language": "python",
   "name": "world"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
