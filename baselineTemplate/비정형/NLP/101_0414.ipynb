{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b4c7e1-811b-4d56-bb7c-f6c84e3b7a9b",
   "metadata": {},
   "source": [
    "# 10 비정형_NLP\n",
    "\n",
    "# 1. 분석 환경 준비\n",
    "## 1.1. 데이터 불러오기\n",
    "분석하려는 데이터를 가져오는 작업\n",
    "\n",
    "* 파이썬 라이브러리 Pandas 이용\n",
    "\n",
    "### 1.1.1. CSV 파일\n",
    "read_csv 메소드 이용\n",
    "\n",
    "### 1.1.2. Json 파일\n",
    "json.loads 메소드 이용하여  JSON 포맷 데이터를 Python 객체로 읽기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116aa4a7-d0f9-40a4-a87e-8bdee5a08257",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리\n",
    "## 2.1. 결측치 처리 Imputation\n",
    "결측치 유무 확인\n",
    "\n",
    "* 카테고리형 feature가 결측치인 경우 : 해당 행들을 삭제   \n",
    "* 수치형 feature가 결측치인 경우 : 평균값을 채워줌\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3b56d-3395-4d30-ab70-0ed008f6ba7c",
   "metadata": {},
   "source": [
    "\n",
    "## 2.2. 텍스트 처리\n",
    "\n",
    "\\n, & 등 불필요한 문자 처리\n",
    "\n",
    "* 정규표현식을 이용해 깔끔한 문장으로 텍스트 전처리\n",
    "* re.sub 메소드 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874b7f6-b8ef-43b9-ab28-c9c481972811",
   "metadata": {},
   "source": [
    "## 2.3. 토큰화 Tokenization \n",
    "\n",
    "말뭉치(Corpus)를 주어진 단위(Token)로 나누는 과정\n",
    "\n",
    "* 영어에 대한 전처리 nltk 패키지\n",
    "* 한국어에 대한 전처리 konlpy 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734229e3-128a-4665-bdbb-bb29e7206734",
   "metadata": {},
   "source": [
    "## 2.4. 불용어 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa54bfa-e497-4598-9fb3-3a31f6bdb1c4",
   "metadata": {},
   "source": [
    "작업 전에 삭제해야 하는 일련의 단어를 의미하기도 하지만 유용한 정보가 거의 없는 매우 자주 등장하\n",
    "는 단어를 의미\n",
    "\n",
    "* nltk의 stopwords(불용어 리스트, 179개)를 사용하여 토큰화된 단어에서 불용어를 찾고 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8494ed-12ef-4c9a-adf6-2aa42e3ffd21",
   "metadata": {},
   "source": [
    "## 2.5. 어간 추출\n",
    "단어의 어간을 구분하여 기본 의미를 유지하면서 어미를 제거\n",
    "\n",
    "* nltk의 PorterStemmer()를 이용하여 단어의 어미를 제거하여 어간을 바꿈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b28fa-ac4e-4af7-9c81-d4a442329ac6",
   "metadata": {},
   "source": [
    "## 2.6. 품사 태깅 POS Tagging\n",
    "\n",
    "주어진 텍스트를 형태소 단위로 나눈 뒤, 각 형태소에 해당 품사를 태깅하여 리스트화 \n",
    "\n",
    "* nltk의 pos_tag 메소드 이용하여 태그를 사용해 특정 품사를 찾음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f17b2-0807-45a0-b10d-a414e3034b57",
   "metadata": {},
   "source": [
    "## 2.7. 패딩 Padding\n",
    "\n",
    "딥러닝 모델에 넣기 위하여 가변 길이 시퀀스를 채워서 똑같은 길이의 데이터 생성\n",
    "\n",
    "* pad_sequences(X_train, maxlen = 100) 메소드 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b31cc-da03-406a-84ee-1eca0cd8c9b4",
   "metadata": {},
   "source": [
    "# 3. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ad589-0672-4984-b500-ad4c9a1f04d2",
   "metadata": {},
   "source": [
    "## 3.1. 변수 정의\n",
    "X : 독립 변수 (자연어 데이터)   \n",
    "y : 종속 변수 (라벨, 타겟)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6452420-110b-4ccd-b645-3798be9bf1b9",
   "metadata": {},
   "source": [
    "## 3.2. 벡터화 CountVectorizer\n",
    "\n",
    "입력된 문장을 토큰화(Tokenize)하여 토큰의 등장 빈도 벡터로 바꿔주는 기법\n",
    "\n",
    "* CountVectorizer 메소드 이용\n",
    "* 벡터화 적용 후 모델학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249fc449-4ec4-41ce-b24c-900bbc3681a5",
   "metadata": {},
   "source": [
    "## 3.3. TF-IDF\n",
    "\n",
    "TF(단어 빈도, term frequency) : 특정한 단어가 문서 내에 얼마나 자주 등장하는지를 나타내는 값   \n",
    "IDF(역문서 빈도, inverse document frequency) : 단어 자체가 문서군 내에서 자주 사용하여 얼마나 그 단어가 흔하게 등장하는지를 나타내는 값의 역수   \n",
    "를 곱한 값\n",
    "\n",
    "\n",
    "* 특정 문서 내에서 단어 빈도가 높을 수록, 그리고 전체 문서들 중 그 단어를 포함한 문서가 적을 수록 TF-IDF값이 높아짐\n",
    "\n",
    "* 모든 문서에 흔하게 나타나는 단어를 걸러냄\n",
    "\n",
    "* 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰임\n",
    "\n",
    "* TfidfVectorizer 메소드 이용하여 데이터 셋 변환\n",
    "\n",
    "* 이후 tfidf_vect.transform 메소드 이용\n",
    "\n",
    "* TF-IDF 적용 후 모델학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5a1e2-969f-4439-9df4-8a74024faafe",
   "metadata": {},
   "source": [
    "## 3.4. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f847a03-372d-4242-8f61-4bcc9ddecc27",
   "metadata": {},
   "source": [
    "### 3.4.1. 분류 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1a876-6082-4b06-8bbf-c420796ffe3d",
   "metadata": {},
   "source": [
    "### 3.4.1.1. Logistic Regression\n",
    "\n",
    "특정 카테고리에 속할지를 0과 1사이의 연속적인 확률로 예측하는 회귀 알고리즘\n",
    "\n",
    "그런 다음, 확률에 기반하여 특정 데이터가 어떤 카테고리에 속할지를 결정하게 되고, 궁극적으로 classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbee280-3090-4852-a206-f99ac8533bd8",
   "metadata": {},
   "source": [
    "### 3.4.2. RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03bc49-7f04-4945-96fc-3e286ede3237",
   "metadata": {},
   "source": [
    "딥러닝 순환신경망, 이전의 계산으로부터 나온 결과를 고려하여 같은 일을 매 샘플마다 반복해서 수행\n",
    "\n",
    "* 3차원 배열 입력값으로 요구\n",
    "\n",
    "Tensor : 하나의 텐서는 모델에 들어가는 벡터   \n",
    "Time Step : 하나의 타임 스텝은 텐서에서 하나의 관측치   \n",
    "Feature :  한 feature는 그 타임 스텝에서 하나의 관측치  \n",
    "\n",
    "* 다양한 형태 \n",
    "\n",
    "one to one : 순환이 적용되지 않아 RNN으로 적합하지 않음   \n",
    "one to many : 하나의 이미지를 받아 설명하는 문장 내보냄, ex)이미지 캡셔닝   \n",
    "many to one : 하나의 문장을 받아 결론을 지음, ex) 해당 문장이 긍정인지 부정인지   \n",
    "many to many 1 : sequential 벡터를 입력받아 sequential 벡터로 출력, ex) 번역할 문장을 받아 다시 번역된 문장을 내놓음(기계번역)  \n",
    "many to many 2 : squential 벡터 입력받는 즉시 squential 벡터 바로 출력, ex) 프레임 단위의 비디오 분류  \n",
    "\n",
    "\n",
    "#### 3.4.2.1 RNN 모델 설계\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "* Embedding : 데이터 전처리 과정을 통해 입력된 값을 받아 다음 층이 알아들을 수 있는 형태로 변환하는 역할     \n",
    "    모델 설정 부분의 맨 처음   \n",
    "    (ex. add(Embedding(불러온 단어의 총 개수,문장당 단어수)) )\n",
    "* SimpleRNN : 은닉 상태 크기를 설정하여 이전 timestep의 출력이 다음 timestep으로 완전히 연결된 모델\n",
    "* Dense : 1차원 배열을 뉴럴넷에 입력 (오로지 퍼셉트론으로 이루어짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83286d6-52c5-420b-b813-56af578b6153",
   "metadata": {},
   "source": [
    "### 3.4.2.2. 모델 컴파일\n",
    "\n",
    "model.complie   \n",
    "생성 모델과 학습 알고리즘(옵티마이저)을 붙이기 위하여 학습할 수 있는 상태로 만들어 주도록 컴파일\n",
    "\n",
    "* optimizer : 최적화 방법 \n",
    "* loss : 손실함수, 회귀의 경우 mse, 분류일 경우 categorical_crossentropy\n",
    "* metrix : 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf5dc35-329b-464e-bd38-86a46306ae0f",
   "metadata": {},
   "source": [
    "### 3.4.2.3. 모델 학습\n",
    "\n",
    "history = model.fit\n",
    "\n",
    "* 모델을 history 라는 매개변수에 저장하게 되면 모델에서 학습했던 자취들이 남아있도록 함\n",
    "* epochs : 에포크\n",
    "* validation_split : 모델 검증\n",
    "* batch_size : 배치사이즈\n",
    "* callbacks : 콜백함수 사용\n",
    "    * EarlyStopping : 모델 성능 향상이 없는 경우 학습을 중지\n",
    "    * ModelCheckpoint : 가장 validation performance 가 좋은 모델을 저장\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614638b5-6f53-42de-80ad-d144480dd0f2",
   "metadata": {},
   "source": [
    "# 4. 모델 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc7f37-7981-418e-ac1e-b38291cfe4bb",
   "metadata": {},
   "source": [
    "## 4.1. 분류 모델 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9398e7-03d7-4002-867a-0ab694301f4e",
   "metadata": {},
   "source": [
    "### 4.1.1. Accuracy\n",
    "\n",
    "올바르게 예측된 데이터의 수를 전체 데이터의 수로 나눈 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3377792-77fe-4979-aa88-c5fd5782fbcd",
   "metadata": {},
   "source": [
    "### 4.1.2. F1-score\n",
    "\n",
    "정밀도와 재현율의 조화 평균\n",
    "\n",
    "* precision과 recall이 0 에 가까울수록 F1 score도 동일하게 낮은 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17742b-5883-465a-bcf2-dd5ea51d7157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world",
   "language": "python",
   "name": "world"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
