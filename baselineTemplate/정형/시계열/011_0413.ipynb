{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec4ebf2b-2cae-4383-bfe3-d5aed817bf97",
   "metadata": {},
   "source": [
    "# 01 정형_시계열\n",
    "\n",
    "# 1. 분석 환경 준비\n",
    "## 1.1. 데이터 불러오기\n",
    "분석하려는 데이터를 가져오는 작업\n",
    "\n",
    "* 파이썬 라이브러리 Pandas 이용\n",
    "\n",
    "* read_csv 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77451974-0fe2-43c6-bae4-cd15a430116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01f464b-7ae4-443a-8ae5-c0a96291f845",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd8af6-e94b-402b-b288-1315af2a7af1",
   "metadata": {},
   "source": [
    "## 2.1. Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c30db8-5452-421b-a765-fe4394e2b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_col(dataframe):\n",
    "    missing_col = []\n",
    "    for col in dataframe.columns:\n",
    "        missing_values = sum(dataframe[col].isna())\n",
    "        is_missing = True if missing_values >= 1 else False\n",
    "        if is_missing:\n",
    "            print(f'결측치가 있는 컬럼은: {col} 입니다')\n",
    "            print(f'해당 컬럼에 총 {missing_values} 개의 결측치가 존재합니다.')\n",
    "            missing_col.append([col, dataframe[col].dtype])\n",
    "    if missing_col == []:\n",
    "        print('결측치가 존재하지 않습니다')\n",
    "    return missing_col\n",
    "\n",
    "missing_col = check_missing_col(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed0115-1c1d-48e3-b2f2-d4da36f8f9a2",
   "metadata": {},
   "source": [
    "### 2.1.1. 결측시 있을시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58567904-ae72-4a67-81ca-bc14bf5c16b1",
   "metadata": {},
   "source": [
    "#### 2.1.1.1. 결측치가 있는 row 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c882a9-97c5-4d53-b592-28c727167a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isna().sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8cc2df-c897-435d-9a87-a3e99d7b6cfa",
   "metadata": {},
   "source": [
    "#### 2.1.1.2. 결측치 처리\n",
    "\n",
    "* 시계열 이므로 삭제 X, 앞 뒤 값 평균 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512472c-c595-47d4-b866-2bfbd9f2d6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "759c20cb-a466-4897-90d5-666ef981cfed",
   "metadata": {},
   "source": [
    "## 2.2. Label Encoding\n",
    "범주(카테고리)형 데이터 존재 시 문자열을 수치형으로 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83cee02-d3af-4a9a-af9a-bb911946286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨인코딩을 하기 위함 dictionary map 생성 함수\n",
    "def make_label_map(dataframe):\n",
    "    label_maps = {}\n",
    "    for col in dataframe.columns:\n",
    "        if dataframe[col].dtype=='object':\n",
    "            label_map = {'unknown':0}\n",
    "            for i, key in enumerate(dataframe[col].unique()):\n",
    "                label_map[key] = i+1  #새로 등장하는 유니크 값들에 대해 1부터 1씩 증가시켜 키값을 부여해줍니다.\n",
    "            label_maps[col] = label_map\n",
    "    print(label_maps)\n",
    "    return label_maps\n",
    "\n",
    "# 각 범주형 변수에 인코딩 값을 부여하는 함수\n",
    "def label_encoder(dataframe, label_map):\n",
    "    for col in dataframe.columns:\n",
    "        if dataframe[col].dtype=='object':\n",
    "            dataframe[col] = dataframe[col].map(label_map[col])\n",
    "            dataframe[col] = dataframe[col].fillna(label_map[col]['unknown']) #혹시 모를 결측값은 unknown의 값(0)으로 채워줍니다.\n",
    "    return dataframe\n",
    "\n",
    "df = label_encoder(df, make_label_map(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4989cf-307c-4143-b9f8-38d75bdf94a9",
   "metadata": {},
   "source": [
    "## 2.3. Datetime Strip\n",
    "\n",
    "년, 월, 일 로 데이터 쪼개서 각 열로 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77718af-25ea-400d-bb94-f7e147f91240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_datetime(dataframe):\n",
    "    year = []\n",
    "    month = []\n",
    "    day = []\n",
    "\n",
    "    for date in dataframe.Datetime:\n",
    "        year_point, month_point, day_point = date.split('-') # - 기준으로 string을 나누고 list로 만듦 \n",
    "                                                             # ex) '2016-04-01' -> ['2016', '04', '01']\n",
    "        year.append(int(year_point))\n",
    "        month.append(int(month_point))\n",
    "        day.append(int(day_point))\n",
    "    return year, month, day\n",
    "\n",
    "year, month, day = seperate_datetime(df)\n",
    "    \n",
    "df['year'] = year\n",
    "df['month'] = month\n",
    "df['day'] = day\n",
    "\n",
    "df = df.drop('Datetime', axis = 1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158545a0-8f01-4081-9729-224261587b7b",
   "metadata": {},
   "source": [
    "## 2.4. Stationary time series\n",
    "\n",
    "VAR, ARIMA 등 모델을 학습하기 위해 시계열 정상성 확인\n",
    "\n",
    "### 2.4.1. 정상성 확인\n",
    "\n",
    "* ADF(Advanced Dickey-Fuller test) test statistic 및 p-value 확인\n",
    "\n",
    "p-value가 0.05(5%) 보다 크면  유의미한 값 X    \n",
    "(귀무가설(null hypothesis : 시계열이 안정적이지 않다.)을 기각할 수 없음)   \n",
    "\n",
    "-> 시계열이 안정적이지 않다고 결론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2b74e-89a2-4c40-bb89-0c3d5071918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def pvalue(col, df):\n",
    "    adfuller_test = adfuller(df[col], autolag= \"AIC\")\n",
    "    print(col, \"ADF test statistic: {}\".format(adfuller_test[0]))\n",
    "    print(col, \"p-value: {}\".format(adfuller_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbeb29-3c71-45f6-983a-74164d532dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns[:]:\n",
    "    pvalue(i, df)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a95f394-4b7a-4f9c-8313-8e5f9b895910",
   "metadata": {},
   "source": [
    "### 2.4.2. 차분 differencing\n",
    "\n",
    "stationary 상태가 아닐시 (위에서 p-value가 0.05(5%) 보다 크면), \n",
    "\n",
    "차분을 취하고 나서 stationary를 확인 (p-value가 0.05(5%) 보다 작은지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d98794-9bf8-425c-8407-4848197758e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0aef4e-b488-49d3-8b8f-a5c824b1bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_diff.columns[:]:\n",
    "    pvalue(i, df_diff)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7bb47-eb1c-4032-a55e-a27814249969",
   "metadata": {},
   "source": [
    "## 2.5. Normalize\n",
    "\n",
    "RNN/LSTM/GRU 등 모델을 학습하기 위해 정규화 사용\n",
    "\n",
    "데이터를 표준화 할때, 오직 학습 데이터만 스케일 변환(scaler transformation)에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e2799-b5f1-43f4-b9fc-de83457139f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_normalize(df, time_steps, for_periods):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        data: dataframe with dates and price data\n",
    "    output: \n",
    "        X_train, y_train: data from 2013/1/1-2018/12/31 \n",
    "        X_test : data from 2019- \n",
    "        sc :     insantiated MinMaxScaler object fit to the training data \n",
    "    \"\"\"\n",
    "    # create training and test set \n",
    "    ts_train = df[:'2018'].iloc[:,0:1].values\n",
    "    ts_test = df['2019':].iloc[:,0:1].values \n",
    "    ts_train_len = len(ts_train)\n",
    "    ts_test_len = len(ts_test)\n",
    "    \n",
    "    # scale the data \n",
    "    from sklearn.preprocessing import MinMaxScaler \n",
    "    sc = MinMaxScaler(feature_range=(0,1))\n",
    "    ts_train_scaled = sc.fit_transform(ts_train)\n",
    "    \n",
    "    # create training data of s samples and t time steps \n",
    "    X_train = [] \n",
    "    y_train = [] \n",
    "    for i in range(time_steps, ts_train_len-1):\n",
    "        X_train.append(ts_train_scaled[i-time_steps:i, 0])\n",
    "        y_train.append(ts_train_scaled[i:i+for_periods, 0])\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    \n",
    "    # Reshaping X_train for efficient modelling \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1 ))\n",
    "    \n",
    "    inputs = pd.concat((all_data[\"Adj Close\"][:'2018'], all_data[\"Adj Close\"]['2019':]), axis=0).values\n",
    "    inputs = inputs[len(inputs)-len(ts_test)-time_steps:]\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "    inputs = sc.transform(inputs)\n",
    "    \n",
    "    # Preparing X_test \n",
    "    X_test = [] \n",
    "    for i in range(time_steps, ts_test_len + time_steps - for_periods):\n",
    "        X_test.append(inputs[i-time_steps:i,0])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    \n",
    "    return X_train, y_train , X_test, sc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591594d7-1db5-4639-add3-0578a454081c",
   "metadata": {},
   "source": [
    "# 3. 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c2150-68f8-44d3-a3b2-1c8448c5e3d9",
   "metadata": {},
   "source": [
    "## 3.1. 변수 정의\n",
    "\n",
    "* X : 독립 변수 (피쳐)\n",
    "* y : 종속 변수 (타켓)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1acf55-1426-4e28-bdab-577773277585",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['id', 'Target'], axis=1)\n",
    "y = df['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24183ef1-7dbf-4e52-95f0-d6dcdf81efbb",
   "metadata": {},
   "source": [
    "## 3.2. 모델 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc8d33-e59d-40c7-8f9b-245b915194d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2.1. 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4d637-fc30-485c-9ace-698d51b1f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression() # 모델 정의\n",
    "model.fit(X, y) # 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b46f48-3d91-491a-ae47-a0246dc7802c",
   "metadata": {},
   "source": [
    "### 3.2.2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efa125-0093-4e4d-acc3-fa7a27d6f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rnn_model(X_train, y_train, X_test, sc):\n",
    "    \"\"\"\n",
    "    create single layer rnn model trained on X_train and y_train \n",
    "    and make predictions on the X_test data \n",
    "    \"\"\"\n",
    "    # create a model \n",
    "    from keras.models import Sequential \n",
    "    from keras.layers import Dense, SimpleRNN \n",
    "    \n",
    "    my_rnn_model = Sequential()\n",
    "    my_rnn_model.add(SimpleRNN(32, return_sequences = True))\n",
    "    my_rnn_model.add(SimpleRNN(32))\n",
    "    my_rnn_model.add(Dense(2)) # The time step of the output \n",
    "    \n",
    "    my_rnn_model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
    "    \n",
    "    # fit the RNN model \n",
    "    my_rnn_model.fit(X_train,y_train, epochs = 100, batch_size = 150, verbose = 0) \n",
    "    \n",
    "    # Finalizing predictions \n",
    "    rnn_predictions = my_rnn_model.predict(X_test)\n",
    "    from sklearn.preprocessing import MinMaxScaler \n",
    "    rnn_predictions = sc.inverse_transform(rnn_predictions)\n",
    "    \n",
    "    return my_rnn_model, rnn_predictions\n",
    "\n",
    "my_rnn_model, rnn_predictions = simple_rnn_model(X_train, y_train, X_test)\n",
    "rnn_predictions[1:10]\n",
    "\n",
    "def actual_pred_plot(preds):\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition\n",
    "    \"\"\"\n",
    "    actual_pred = pd.DataFrame(columns = ['Adj. Close', 'prediction'])\n",
    "    actual_pred['Adj. Close'] = all_data.loc['2019':,'Adj Close'][0:len(preds)]\n",
    "    actual_pred['prediction'] = preds[:,0]\n",
    "    \n",
    "    from keras.metrics import MeanSquaredError \n",
    "    m = MeanSquaredError()\n",
    "    m.update_state(np.array(actual_pred['Adj. Close']), np.array(actual_pred['prediction']))\n",
    "    \n",
    "    return (m.result().numpy(), actual_pred.plot())\n",
    "\n",
    "X_train, y_train, X_test, sc = ts_train_test_normalize(all_data, 5,2)\n",
    "my_rnn_model, rnn_predictions = simple_rnn_model(X_train, y_train, X_test, sc)\n",
    "rnn_predictions[1:10]\n",
    "actual_pred_plot(rnn_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b40388-b503-4590-9c85-2feba4c3f459",
   "metadata": {},
   "source": [
    "### 3.2.3. VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a1bc1-318e-42f6-a034-82abb207f563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def var_modeling(time)\n",
    "\n",
    "    train = df_diff.iloc[:-time,:]\n",
    "    test = df_diff.iloc[-time:,:]\n",
    "    forecasting_model = VAR(train)\n",
    "    results_aic = []\n",
    "    temp = {}\n",
    "\n",
    "    for p in range(1,10): #1부터 10까지 적합한 순서에 대한 AIC 점수를 찾기 위해 반복문\n",
    "        results = forecasting_model.fit(p)\n",
    "        results_aic.append(results.aic)\n",
    "        temp[p] = results.aic\n",
    "\n",
    "    p = min(temp, key=temp.get) # AIC가 낮을 수록 모형의 적합도가 높으므로, 가장 낮은 AIC 점수 추출\n",
    "\n",
    "    sns.set()\n",
    "    plt.plot(list(np.arange(1,10,1)), results_aic)\n",
    "    plt.xlabel(\"Order\")\n",
    "    plt.ylabel(\"AIC\")\n",
    "    plt.show()\n",
    "\n",
    "    results = forecasting_model.fit(p)\n",
    "    #results.summary()\n",
    "\n",
    "    laaged_values = train.values[-p:]\n",
    "    forecast = pd.DataFrame(results.forecast(y= laaged_values, steps=time), index = test.index, columns= columns)\n",
    "    # 학습된 모델에 p일 동안의 훈련을 넣어 향후 time일 동안의 테스트 데이터를 예측\n",
    "    forecast[\"페이지뷰_fc\"] = df[\"페이지뷰\"].iloc[-time-1] + forecast['페이지뷰'].cumsum() ##나중에 페이지뷰 수정\n",
    "\n",
    "y_test = test['페이지뷰'].values\n",
    "y_pred = test['페이지뷰_fc'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8c4e6-a84f-4036-8fca-5b5998f42384",
   "metadata": {},
   "source": [
    "# 4. 모델 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb641c-8e75-402f-80d3-897533ff4a1d",
   "metadata": {},
   "source": [
    "## 4.1. 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268638c-82db-4570-ace2-f525af668a58",
   "metadata": {},
   "source": [
    "### 4.1.1. NMAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fcbe00-c25e-4431-bbd2-b11d6bcd0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def nmae(true, pred):\n",
    "    mae = np.mean(np.abs(true-pred))\n",
    "    score = mae / np.mean(np.abs(true))\n",
    "    return score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'모델 NMAE: {nmae(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5ebbed-31a1-4f62-b741-87efce7d6e97",
   "metadata": {},
   "source": [
    "### 4.1.2. RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9275563-34fc-453a-aaba-184777853854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RMSE = mean_squared_error(y_test, y_pred)**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world",
   "language": "python",
   "name": "world"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
